#!/bin/bash

echo "ğŸš€ Setting up Local RAG Solution..."

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollama is not installed. Please install Ollama first:"
    echo "   Visit: https://ollama.ai"
    exit 1
fi

echo "âœ… Ollama found"

# Pull required models
echo "ğŸ“¥ Pulling Ollama models..."
echo "   Pulling embedding model: bge-m3:latest"
ollama pull bge-m3:latest

echo "   Pulling generation model: gemma3:4b"
ollama pull gemma3:4b

# Setup backend
echo "ğŸ Setting up Python backend..."
cd rag_backend

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

echo "âœ… Backend setup complete"

# Setup frontend
echo "âš›ï¸  Setting up React frontend..."
cd ../rag_frontend

# Install npm dependencies
npm install

echo "âœ… Frontend setup complete"

cd ..

echo "ğŸ‰ Setup complete!"
echo ""
echo "To start the application:"
echo "1. Start the backend: cd rag_backend && source venv/bin/activate && python main.py"
echo "2. Start the frontend: cd rag_frontend && npm start"
echo ""
echo "The application will be available at: http://localhost:3000"
